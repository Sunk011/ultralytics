#!/usr/bin/env python3
"""
YOLOè¯„ä»·å·¥å…·æµ‹è¯•æ–‡ä»¶
"""

import os
import sys
import json
import tempfile
import shutil
from pathlib import Path
from PIL import Image
import numpy as np

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from yolo_evaluator import YOLOEvaluator

def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    print("åˆ›å»ºæµ‹è¯•æ•°æ®...")
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    test_dir = Path("test_data")
    if test_dir.exists():
        shutil.rmtree(test_dir)
    
    img_dir = test_dir / "images"
    pred_dir = test_dir / "predictions"
    gt_dir = test_dir / "ground_truths"
    
    img_dir.mkdir(parents=True)
    pred_dir.mkdir(parents=True)
    gt_dir.mkdir(parents=True)
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    image_size = (640, 480)  # width, height
    num_images = 5
    
    for i in range(num_images):
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        img = Image.new('RGB', image_size, color='white')
        img_path = img_dir / f"test_image_{i:03d}.jpg"
        img.save(img_path)
        
        # åˆ›å»ºå¯¹åº”çš„é¢„æµ‹æ ‡ç­¾ (å½’ä¸€åŒ–åæ ‡ + ç½®ä¿¡åº¦)
        pred_path = pred_dir / f"test_image_{i:03d}.txt"
        with open(pred_path, 'w') as f:
            # ç±»åˆ«0: ä¸­å¿ƒåœ¨(0.3, 0.3), å¤§å°(0.2, 0.2), ç½®ä¿¡åº¦0.8
            f.write("0 0.3 0.3 0.2 0.2 0.8\n")
            # ç±»åˆ«1: ä¸­å¿ƒåœ¨(0.7, 0.7), å¤§å°(0.15, 0.15), ç½®ä¿¡åº¦0.9
            f.write("1 0.7 0.7 0.15 0.15 0.9\n")
            if i > 2:  # åé¢çš„å›¾åƒæ·»åŠ æ›´å¤šé¢„æµ‹
                f.write("0 0.5 0.5 0.1 0.1 0.7\n")
        
        # åˆ›å»ºå¯¹åº”çš„çœŸå®æ ‡ç­¾ (å½’ä¸€åŒ–åæ ‡ï¼Œæ— ç½®ä¿¡åº¦)
        gt_path = gt_dir / f"test_image_{i:03d}.txt"
        with open(gt_path, 'w') as f:
            # ç±»åˆ«0: ä¸­å¿ƒåœ¨(0.32, 0.28), å¤§å°(0.18, 0.22) - ä¸é¢„æµ‹æ¥è¿‘ä½†æœ‰åå·®
            f.write("0 0.32 0.28 0.18 0.22\n")
            # ç±»åˆ«1: ä¸­å¿ƒåœ¨(0.68, 0.72), å¤§å°(0.16, 0.14) - ä¸é¢„æµ‹æ¥è¿‘ä½†æœ‰åå·®
            f.write("1 0.68 0.72 0.16 0.14\n")
            if i > 1:  # åé¢çš„å›¾åƒæ·»åŠ æ›´å¤šçœŸå®æ ‡ç­¾
                f.write("2 0.1 0.1 0.05 0.05\n")
    
    # åˆ›å»ºç±»åˆ«åç§°æ–‡ä»¶
    class_names = {
        0: "äºº",
        1: "è½¦",
        2: "è‡ªè¡Œè½¦"
    }
    
    with open(test_dir / "class_names.json", 'w', encoding='utf-8') as f:
        json.dump(class_names, f, ensure_ascii=False, indent=2)
    
    print(f"æµ‹è¯•æ•°æ®å·²åˆ›å»ºåœ¨: {test_dir}")
    print(f"  - å›¾åƒæ•°é‡: {num_images}")
    print(f"  - å›¾åƒå°ºå¯¸: {image_size}")
    print(f"  - ç±»åˆ«æ•°é‡: {len(class_names)}")
    
    return test_dir

def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    print("\n" + "="*60)
    print("æµ‹è¯•åŸºæœ¬åŠŸèƒ½")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_dir = create_test_data()
    
    try:
        # åŠ è½½ç±»åˆ«åç§°
        with open(test_dir / "class_names.json", 'r', encoding='utf-8') as f:
            class_names = json.load(f)
        
        # åˆ›å»ºè¯„ä»·å™¨
        evaluator = YOLOEvaluator(
            pred_dir=test_dir / "predictions",
            gt_dir=test_dir / "ground_truths", 
            img_dir=test_dir / "images",
            conf_threshold=0.5,
            iou_threshold=0.5,
            class_names=class_names
        )
        
        # è¿è¡Œè¯„ä»·
        metrics = evaluator.run_evaluation()
        
        if metrics:
            print("\nâœ… åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡!")
            print(f"mAP: {metrics['mAP']:.4f}")
            print(f"ç±»åˆ«æ•°é‡: {metrics['num_classes']}")
            
            # ä¿å­˜ç»“æœ
            output_dir = test_dir / "results"
            evaluator.save_results(output_dir)
            
            # ç”Ÿæˆå›¾è¡¨
            evaluator.plot_class_ap_chart(output_dir)
            evaluator.plot_precision_recall_curve(output_dir)
            
            print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
            
            return True
        else:
            print("âŒ åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥!")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # æ¸…ç†æµ‹è¯•æ•°æ®
        if test_dir.exists():
            shutil.rmtree(test_dir)

def test_real_data():
    """æµ‹è¯•çœŸå®æ•°æ®"""
    print("\n" + "="*60)
    print("æµ‹è¯•çœŸå®æ•°æ®")
    print("="*60)
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨çœŸå®æ•°æ®
    pred_dir = Path("asset/pt_labels")
    gt_dir = Path("asset/gt_label") 
    img_dir = Path("asset/images")  # å‡è®¾å›¾åƒåœ¨è¿™é‡Œ
    
    if not all([pred_dir.exists(), gt_dir.exists()]):
        print("âŒ æœªæ‰¾åˆ°çœŸå®æ•°æ®ç›®å½•ï¼Œè·³è¿‡æµ‹è¯•")
        return False
    
    if not img_dir.exists():
        print("âš ï¸  æœªæ‰¾åˆ°å›¾åƒç›®å½•ï¼Œéœ€è¦æŒ‡å®šæ­£ç¡®çš„å›¾åƒè·¯å¾„")
        return False
    
    try:
        # åˆ›å»ºè¯„ä»·å™¨
        evaluator = YOLOEvaluator(
            pred_dir=pred_dir,
            gt_dir=gt_dir,
            img_dir=img_dir,
            conf_threshold=0.25,
            iou_threshold=0.5
        )
        
        # è¿è¡Œè¯„ä»·
        metrics = evaluator.run_evaluation()
        
        if metrics:
            print("\nâœ… çœŸå®æ•°æ®æµ‹è¯•é€šè¿‡!")
            print(f"mAP: {metrics['mAP']:.4f}")
            
            # ä¿å­˜ç»“æœ
            output_dir = Path("real_data_results")
            evaluator.save_results(output_dir)
            evaluator.plot_class_ap_chart(output_dir)
            evaluator.plot_precision_recall_curve(output_dir)
            
            # è®¡ç®—COCO mAP
            coco_map = evaluator.calculate_map_at_multiple_ious()
            print(f"\nCOCO mAP: {coco_map['mAP@[0.5:0.95]']:.4f}")
            
            return True
        else:
            print("âŒ çœŸå®æ•°æ®æµ‹è¯•å¤±è´¥!")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_edge_cases():
    """æµ‹è¯•è¾¹ç¼˜æƒ…å†µ"""
    print("\n" + "="*60)
    print("æµ‹è¯•è¾¹ç¼˜æƒ…å†µ")
    print("="*60)
    
    test_dir = Path("edge_case_test")
    if test_dir.exists():
        shutil.rmtree(test_dir)
    
    img_dir = test_dir / "images"
    pred_dir = test_dir / "predictions"
    gt_dir = test_dir / "ground_truths"
    
    img_dir.mkdir(parents=True)
    pred_dir.mkdir(parents=True)
    gt_dir.mkdir(parents=True)
    
    try:
        # æµ‹è¯•1: ç©ºé¢„æµ‹æ–‡ä»¶
        img = Image.new('RGB', (640, 480), color='white')
        img.save(img_dir / "empty_pred.jpg")
        
        with open(pred_dir / "empty_pred.txt", 'w') as f:
            pass  # ç©ºæ–‡ä»¶
        
        with open(gt_dir / "empty_pred.txt", 'w') as f:
            f.write("0 0.5 0.5 0.1 0.1\n")
        
        # æµ‹è¯•2: ç©ºçœŸå®æ ‡ç­¾æ–‡ä»¶
        img.save(img_dir / "empty_gt.jpg")
        
        with open(pred_dir / "empty_gt.txt", 'w') as f:
            f.write("0 0.5 0.5 0.1 0.1 0.8\n")
        
        with open(gt_dir / "empty_gt.txt", 'w') as f:
            pass  # ç©ºæ–‡ä»¶
        
        # æµ‹è¯•3: ä½ç½®ä¿¡åº¦é¢„æµ‹
        img.save(img_dir / "low_conf.jpg")
        
        with open(pred_dir / "low_conf.txt", 'w') as f:
            f.write("0 0.5 0.5 0.1 0.1 0.1\n")  # ä½ç½®ä¿¡åº¦
        
        with open(gt_dir / "low_conf.txt", 'w') as f:
            f.write("0 0.5 0.5 0.1 0.1\n")
        
        # åˆ›å»ºè¯„ä»·å™¨
        evaluator = YOLOEvaluator(
            pred_dir=pred_dir,
            gt_dir=gt_dir,
            img_dir=img_dir,
            conf_threshold=0.5,
            iou_threshold=0.5
        )
        
        # è¿è¡Œè¯„ä»·
        metrics = evaluator.run_evaluation()
        
        print("âœ… è¾¹ç¼˜æƒ…å†µæµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âŒ è¾¹ç¼˜æƒ…å†µæµ‹è¯•å¤±è´¥: {e}")
        return False
    
    finally:
        if test_dir.exists():
            shutil.rmtree(test_dir)

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("YOLOè¯„ä»·å·¥å…·æµ‹è¯•å¥—ä»¶")
    print("="*60)
    
    test_results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_results.append(("åŸºæœ¬åŠŸèƒ½æµ‹è¯•", test_basic_functionality()))
    test_results.append(("è¾¹ç¼˜æƒ…å†µæµ‹è¯•", test_edge_cases()))
    # test_results.append(("çœŸå®æ•°æ®æµ‹è¯•", test_real_data()))  # éœ€è¦çœŸå®å›¾åƒç›®å½•
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "="*60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*60)
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†!")
        return True
    else:
        print("âš ï¸  æœ‰æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ")
        return False

if __name__ == "__main__":
    main()
