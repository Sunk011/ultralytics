# inference && save

# import cv2
# import numpy as np
# from ultralytics import YOLO

# class YoloDetector:
#     """
#     ä¸€ä¸ªä½¿ç”¨YOLOv8æ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹çš„å·¥å…·ç±»ã€‚
#     å®ƒå¯ä»¥å¤„ç†è§†é¢‘æ–‡ä»¶ï¼Œä»¥mmdetectioné£æ ¼ç»˜åˆ¶æ£€æµ‹æ¡†ï¼Œå¹¶ä¿å­˜ç»“æœã€‚
#     """

#     def __init__(self, model_path: str = 'yolov8n.pt'):
#         """
#         åˆå§‹åŒ–æ£€æµ‹å™¨ï¼ŒåŠ è½½YOLOæ¨¡å‹å¹¶ä¸ºæ¯ä¸ªç±»åˆ«åˆ†é…é¢œè‰²ã€‚

#         :param model_path: YOLOæ¨¡å‹çš„è·¯å¾„ (e.g., 'yolov8n.pt'). 
#                            å¦‚æœæ¨¡å‹ä¸å­˜åœ¨ï¼Œultralyticsä¼šè‡ªåŠ¨ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ã€‚
#         """
#         print(f"æ­£åœ¨åŠ è½½ YOLO æ¨¡å‹: {model_path}")
#         try:
#             self.model = YOLO(model_path)
#             # è·å–æ‰€æœ‰ç±»åˆ«åç§°
#             self.class_names = self.model.names
#             print(f"æ¨¡å‹åŠ è½½æˆåŠŸã€‚æ£€æµ‹ç±»åˆ«: {list(self.class_names.values())}")

#             # ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆä¸€ä¸ªå›ºå®šçš„é¢œè‰²ï¼Œç”¨äºç»˜åˆ¶
#             # ä½¿ç”¨éšæœºç§å­ç¡®ä¿æ¯æ¬¡è¿è¡Œé¢œè‰²éƒ½ä¸€æ ·
#             np.random.seed(42) 
#             self.colors = np.random.randint(0, 255, size=(len(self.class_names), 3), dtype=np.uint8)
#         except Exception as e:
#             print(f"é”™è¯¯: æ— æ³•åŠ è½½ YOLO æ¨¡å‹ã€‚è¯·æ£€æŸ¥è·¯å¾„å’Œå®‰è£…ã€‚é”™è¯¯è¯¦æƒ…: {e}")
#             self.model = None

#     def _draw_mmdet_style_box(self, frame, box, score, class_id):
#         """
#         ä»¥mmdetectionçš„é£æ ¼åœ¨å›¾åƒä¸Šç»˜åˆ¶å•ä¸ªæ£€æµ‹æ¡†ã€‚
#         è¿™æ˜¯ä¸€ä¸ªç§æœ‰è¾…åŠ©æ–¹æ³•ã€‚

#         :param frame: è¦ç»˜åˆ¶çš„OpenCVå›¾åƒå¸§ã€‚
#         :param box: åŒ…å«[x1, y1, x2, y2]çš„è¾¹ç•Œæ¡†åæ ‡ã€‚
#         :param score: æ£€æµ‹çš„ç½®ä¿¡åº¦ã€‚
#         :param class_id: æ£€æµ‹åˆ°çš„ç±»åˆ«IDã€‚
#         :return: ç»˜åˆ¶äº†ä¿¡æ¯çš„åŸå§‹frameçš„å‰¯æœ¬ï¼ˆç”¨äºåŠé€æ˜æ•ˆæœï¼‰ã€‚
#         """
#         x1, y1, x2, y2 = map(int, box)
#         color = self.colors[class_id].tolist() # å°†numpyé¢œè‰²è½¬ä¸ºlist
#         class_name = self.class_names[class_id]

#         # --- ç»˜åˆ¶ä¸»è¾¹ç•Œæ¡† ---
#         cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)

#         # --- å‡†å¤‡ç»˜åˆ¶æ–‡æœ¬å’Œå…¶èƒŒæ™¯ ---
#         label = f'{class_name} {score:.2f}'
#         font = cv2.FONT_HERSHEY_SIMPLEX
#         font_scale = 0.7
#         font_thickness = 2
        
#         # è·å–æ–‡æœ¬å°ºå¯¸
#         (text_w, text_h), baseline = cv2.getTextSize(label, font, font_scale, font_thickness)
        
#         # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯æ¡† (æ”¾åœ¨ä¸»æ¡†çš„é¡¶éƒ¨)
#         # ç¡®ä¿èƒŒæ™¯æ¡†ä¸ä¼šè¶…å‡ºå›¾åƒé¡¶éƒ¨
#         label_y1 = max(y1 - text_h - baseline, 0)
#         cv2.rectangle(frame, (x1, label_y1), (x1 + text_w, y1), color, -1) # -1è¡¨ç¤ºå¡«å……

#         # --- ç»˜åˆ¶æ–‡æœ¬ ---
#         # æ–‡æœ¬é¢œè‰²åº”è¯¥æ˜¯å¯¹æ¯”åº¦é«˜çš„é¢œè‰²ï¼Œè¿™é‡Œç”¨ç™½è‰²
#         cv2.putText(frame, label, (x1, y1 - baseline), font, font_scale, (255, 255, 255), font_thickness)

#     def process_video(self, input_path: str, output_path: str, conf_threshold: float = 0.5):
#         """
#         å¤„ç†è¾“å…¥è§†é¢‘ï¼Œè¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œå¹¶å°†ç»“æœä¿å­˜åˆ°è¾“å‡ºè§†é¢‘ã€‚

#         :param input_path: è¾“å…¥è§†é¢‘æ–‡ä»¶çš„è·¯å¾„ã€‚
#         :param output_path: ä¿å­˜å¤„ç†åè§†é¢‘çš„è·¯å¾„ã€‚
#         :param conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„æ£€æµ‹å°†è¢«å¿½ç•¥ã€‚
#         """
#         if not self.model:
#             print("é”™è¯¯ï¼šYOLOæ¨¡å‹æœªåˆå§‹åŒ–ï¼Œæ— æ³•å¤„ç†è§†é¢‘ã€‚")
#             return

#         # æ‰“å¼€è¾“å…¥è§†é¢‘
#         cap = cv2.VideoCapture(input_path)
#         if not cap.isOpened():
#             print(f"é”™è¯¯: æ— æ³•æ‰“å¼€è¾“å…¥è§†é¢‘ '{input_path}'")
#             return

#         # è·å–è§†é¢‘å±æ€§ä»¥åˆ›å»ºè¾“å‡ºè§†é¢‘
#         frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#         frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#         fps = cap.get(cv2.CAP_PROP_FPS)

#         # å®šä¹‰è§†é¢‘ç¼–ç å™¨å’Œåˆ›å»ºVideoWriterå¯¹è±¡
#         # ä½¿ç”¨ 'mp4v' ç¼–ç å™¨æ¥ä¿å­˜ä¸º .mp4 æ–‡ä»¶
#         fourcc = cv2.VideoWriter_fourcc(*'mp4v')
#         out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

#         print(f"å¼€å§‹å¤„ç†è§†é¢‘... æŒ‰ 'q' é”®å¯æå‰ç»ˆæ­¢å¹¶ä¿å­˜å½“å‰è¿›åº¦ã€‚")
        
#         while cap.isOpened():
#             ret, frame = cap.read()
#             if not ret:
#                 break

#             # --- YOLOv8 æ¨ç† ---
#             # stream=True æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œæ›´çœå†…å­˜
#             results = self.model(frame, stream=True, conf=conf_threshold)

#             # åˆ›å»ºä¸€ä¸ªå‰¯æœ¬ç”¨äºç»˜åˆ¶åŠé€æ˜æ•ˆæœ
#             overlay = frame.copy()

#             # éå†æ£€æµ‹ç»“æœ
#             for r in results:
#                 boxes = r.boxes
#                 for box in boxes:
#                     # è·å–è¾¹ç•Œæ¡†åæ ‡ (xyxyæ ¼å¼)
#                     bbox = box.xyxy[0]
#                     # è·å–ç½®ä¿¡åº¦
#                     score = float(box.conf[0])
#                     # è·å–ç±»åˆ«ID
#                     class_id = int(box.cls[0])
                    
#                     # åœ¨ overlay ä¸Šç»˜åˆ¶
#                     self._draw_mmdet_style_box(overlay, bbox, score, class_id)
            
#             # --- åº”ç”¨åŠé€æ˜æ•ˆæœ ---
#             # é€šè¿‡æ··åˆåŸå§‹å¸§å’Œå¸¦æœ‰ç»˜åˆ¶ä¿¡æ¯çš„è¦†ç›–å±‚æ¥å®ç°
#             alpha = 0.6 # é€æ˜åº¦
#             processed_frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)

#             # å°†å¤„ç†åçš„å¸§å†™å…¥è¾“å‡ºæ–‡ä»¶
#             out.write(processed_frame)

#             # (å¯é€‰) å®æ—¶æ˜¾ç¤ºå¤„ç†ç»“æœ
#             # cv2.imshow('YOLOv8 Detection', processed_frame)
#             if cv2.waitKey(1) & 0xFF == ord('q'):
#                 print("ç”¨æˆ·æ‰‹åŠ¨ç»ˆæ­¢ã€‚")
#                 break
        
#         # é‡Šæ”¾æ‰€æœ‰èµ„æº
#         cap.release()
#         out.release()
#         cv2.destroyAllWindows()
#         print(f"è§†é¢‘å¤„ç†å®Œæˆã€‚ç»“æœå·²ä¿å­˜åˆ° '{output_path}'")


# if __name__ == '__main__':
#     # --- ä½¿ç”¨ç¤ºä¾‹ ---

#     # 1. å®ä¾‹åŒ–æ£€æµ‹å™¨ã€‚
#     # ä½¿ç”¨é»˜è®¤çš„ 'yolov8n.pt'ã€‚å¦‚æœæœ¬åœ°æ²¡æœ‰ï¼Œä¼šè‡ªåŠ¨ä¸‹è½½ã€‚
#     # ä½ ä¹Ÿå¯ä»¥æ¢æˆä½ è‡ªå·±çš„è®­ç»ƒæ¨¡å‹ 'path/to/your/best.pt'
#     # detector = YoloDetector(model_path=r'/home/sk/project/jg_project/v001/weights/best.pt')
#     # detector = YoloDetector(model_path=r'./ultralytics/yolo11m-obj365-640-Pretrain.pt')
#     detector = YoloDetector(model_path=r'./jg_project/v001-epoch100-aug/weights/best.pt')

#     # 2. å®šä¹‰è¾“å…¥å’Œè¾“å‡ºè§†é¢‘è·¯å¾„
#     # è¯·å°†ä¸‹é¢ä¸€è¡Œä¸­çš„ "path/to/your/input_video.mp4" æ›¿æ¢ä¸ºæ‚¨çš„è§†é¢‘æ–‡ä»¶å®é™…è·¯å¾„
#     input_video = "./datasets/test-video/720310.mp4"
#     # output_video = "./inference_results/output_detection_video-obj365.mp4"
#     output_video = "./inference_results/output_detection_video-v001-epoch100-aug.mp4"
    
#     # 3. è°ƒç”¨å¤„ç†æ–¹æ³•
#     if detector.model:
#         detector.process_video(input_video, output_video, conf_threshold=0.4)

























# # inference && crop target images
# import cv2
# import numpy as np
# from ultralytics import YOLO
# import os

# class YoloDetector:
#     """
#     ä¸€ä¸ªä½¿ç”¨YOLOv8æ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹çš„å·¥å…·ç±»ã€‚
#     å®ƒå¯ä»¥å¤„ç†è§†é¢‘æ–‡ä»¶ï¼Œä»¥mmdetectioné£æ ¼ç»˜åˆ¶æ£€æµ‹æ¡†ï¼Œå¹¶èƒ½å°†æŒ‡å®šç±»åˆ«çš„ç‰©ä½“è£å‰ªå¹¶ä¿å­˜ã€‚
#     ã€æ–°ç‰¹æ€§ã€‘ä¿å­˜çš„è£å‰ªå›¾ç‰‡ä¼šä»¥æŒä¹…åŒ–çš„æ•°å­—åºåˆ—ï¼ˆ1.jpg, 2.jpg, ...ï¼‰å‘½åã€‚
#     """

#     def __init__(self, model_path: str = 'yolov8n.pt'):
#         """
#         åˆå§‹åŒ–æ£€æµ‹å™¨ï¼ŒåŠ è½½YOLOæ¨¡å‹å¹¶ä¸ºæ¯ä¸ªç±»åˆ«åˆ†é…é¢œè‰²ã€‚
#         """
#         print(f"æ­£åœ¨åŠ è½½ YOLO æ¨¡å‹: {model_path}")
#         try:
#             self.model = YOLO(model_path)
#             self.class_names = self.model.names
#             print(f"æ¨¡å‹åŠ è½½æˆåŠŸã€‚æ£€æµ‹ç±»åˆ«: {list(self.class_names.values())}")
#             self.class_name_to_id = {v: k for k, v in self.class_names.items()}

#             np.random.seed(42)
#             self.colors = np.random.randint(0, 255, size=(len(self.class_names), 3), dtype=np.uint8)
            
#             # ã€é‡å¤§ä¿®æ”¹ã€‘ä¸ºè£å‰ªæ–‡ä»¶çš„å‘½ååˆ›å»ºä¸€ä¸ªå®ä¾‹è®¡æ•°å™¨
#             self.crop_file_counter = 0

#         except Exception as e:
#             print(f"é”™è¯¯: æ— æ³•åŠ è½½ YOLO æ¨¡å‹ã€‚è¯·æ£€æŸ¥è·¯å¾„å’Œå®‰è£…ã€‚é”™è¯¯è¯¦æƒ…: {e}")
#             self.model = None

#     # ã€æ–°å‡½æ•°ã€‘è·å–ç›®å½•ä¸­ç°æœ‰å›¾ç‰‡çš„æœ€å¤§ç¼–å·
#     def get_highest_file_number(self, directory: str) -> int:
#         """
#         æ£€æŸ¥æŒ‡å®šç›®å½•ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºå®ƒã€‚
#         ç„¶åæ‰«æç›®å½•ä¸­æ‰€æœ‰ 'æ•°å­—.jpg' æ ¼å¼çš„æ–‡ä»¶ï¼Œå¹¶è¿”å›å…¶ä¸­æœ€å¤§çš„æ•°å­—ã€‚
#         å¦‚æœç›®å½•ä¸ºç©ºæˆ–æ²¡æœ‰ç¬¦åˆæ ¼å¼çš„æ–‡ä»¶ï¼Œåˆ™è¿”å› 0ã€‚

#         :param directory: è¦æ‰«æçš„æ–‡ä»¶å¤¹ç›®å½•ã€‚
#         :return: æ–‡ä»¶å¤¹ä¸­ç°æœ‰å›¾ç‰‡çš„æœ€å¤§ç¼–å·ã€‚
#         """
#         # ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
#         os.makedirs(directory, exist_ok=True)
        
#         max_num = 0
#         try:
#             files = os.listdir(directory)
#             for filename in files:
#                 # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºjpgæ ¼å¼
#                 if filename.lower().endswith('.jpg'):
#                     # å°è¯•ä»æ–‡ä»¶åä¸­æå–æ•°å­—éƒ¨åˆ†
#                     try:
#                         # å»æ‰ .jpg åç¼€
#                         num_str = os.path.splitext(filename)[0]
#                         num = int(num_str)
#                         if num > max_num:
#                             max_num = num
#                     except ValueError:
#                         # å¦‚æœæ–‡ä»¶åä¸æ˜¯çº¯æ•°å­—ï¼Œåˆ™å¿½ç•¥è¯¥æ–‡ä»¶
#                         continue
#         except Exception as e:
#             print(f"æ‰«æç›®å½•æ—¶å‘ç”Ÿé”™è¯¯: {e}")

#         print(f"æ‰«æç›®å½• '{directory}' å®Œæˆã€‚æ‰¾åˆ°çš„æœ€å¤§æ–‡ä»¶ç¼–å·ä¸º: {max_num}ã€‚")
#         return max_num

#     def _draw_mmdet_style_box(self, frame, box, score, class_id):
#         """
#         ä»¥mmdetectionçš„é£æ ¼åœ¨å›¾åƒä¸Šç»˜åˆ¶å•ä¸ªæ£€æµ‹æ¡†ã€‚
#         """
#         x1, y1, x2, y2 = map(int, box)
#         color = self.colors[class_id].tolist()
#         class_name = self.class_names[class_id]

#         cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)

#         label = f'{class_name} {score:.2f}'
#         font = cv2.FONT_HERSHEY_SIMPLEX
#         font_scale = 0.7
#         font_thickness = 2
#         (text_w, text_h), baseline = cv2.getTextSize(label, font, font_scale, font_thickness)
#         label_y1 = max(y1 - text_h - baseline, 0)
#         cv2.rectangle(frame, (x1, label_y1), (x1 + text_w, y1), color, -1)
#         cv2.putText(frame, label, (x1, y1 - baseline), font, font_scale, (255, 255, 255), font_thickness)


#     def crop_and_save_objects(self, single_frame_result, original_frame, target_class_id: int, save_dir: str):
#         """
#         ä»å•å¸§æ£€æµ‹ç»“æœä¸­è£å‰ªå‡ºæŒ‡å®šç±»åˆ«çš„ç‰©ä½“å¹¶ä»¥é€’å¢æ•°å­—å‘½åä¿å­˜ã€‚

#         :param single_frame_result: æ¥è‡ªYOLOæ¨¡å‹çš„ä¸€å¸§çš„æ£€æµ‹ç»“æœå¯¹è±¡ã€‚
#         :param original_frame: åŸå§‹çš„OpenCVå›¾åƒå¸§ï¼Œç”¨äºè£å‰ªã€‚
#         :param target_class_id: è¦è£å‰ªçš„ç›®æ ‡ç‰©ä½“çš„ç±»åˆ«IDã€‚
#         :param save_dir: ä¿å­˜è£å‰ªåå›¾åƒçš„ç›®å½•ã€‚
#         """
#         boxes = single_frame_result.boxes
#         original_frame = original_frame.copy()
#         for box in boxes:
#             class_id = int(box.cls[0])
            
#             if class_id == target_class_id:
#                 x1, y1, x2, y2 = map(int, box.xyxy[0])
#                 x1, y1 = max(0, x1), max(0, y1)
#                 x2, y2 = min(original_frame.shape[1], x2), min(original_frame.shape[0], y2)
                
#                 if x1 < x2 and y1 < y2:
#                     cropped_object = original_frame[y1:y2, x1:x2]
                    
#                     # ä½¿ç”¨å®ä¾‹è®¡æ•°å™¨æ¥å‘½åæ–‡ä»¶
#                     self.crop_file_counter += 1
#                     filename = f"{self.crop_file_counter}.jpg"
#                     save_path = os.path.join(save_dir, filename)
#                     cv2.imwrite(save_path, cropped_object)

#     # ã€é‡å¤§ä¿®æ”¹ã€‘ä¿®æ”¹äº† process_video å‡½æ•°çš„é€»è¾‘
#     def process_video(self, input_path: str, output_path: str, conf_threshold: float = 0.5,
#                       crop_target_class_name: str = None, crop_save_dir: str = None):
#         """
#         å¤„ç†è¾“å…¥è§†é¢‘ï¼Œè¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œå¹¶å°†ç»“æœä¿å­˜åˆ°è¾“å‡ºè§†é¢‘ã€‚
#         """
#         if not self.model:
#             print("é”™è¯¯ï¼šYOLOæ¨¡å‹æœªåˆå§‹åŒ–ï¼Œæ— æ³•å¤„ç†è§†é¢‘ã€‚")
#             return

#         cropping_enabled = False
#         target_class_id = -1
#         if crop_target_class_name and crop_save_dir:
#             if crop_target_class_name in self.class_name_to_id:
#                 cropping_enabled = True
#                 target_class_id = self.class_name_to_id[crop_target_class_name]
#                 print(f"è£å‰ªåŠŸèƒ½å·²å¯ç”¨ï¼šå°†è£å‰ªç±»åˆ« '{crop_target_class_name}' (ID: {target_class_id}) å¹¶ä¿å­˜è‡³ '{crop_save_dir}'")
                
#                 # åœ¨å¤„ç†å¼€å§‹å‰ï¼Œåˆå§‹åŒ–æ–‡ä»¶è®¡æ•°å™¨
#                 self.crop_file_counter = self.get_highest_file_number(crop_save_dir)
                
#             else:
#                 print(f"è­¦å‘Šï¼šæŒ‡å®šçš„è£å‰ªç±»åˆ« '{crop_target_class_name}' ä¸å­˜åœ¨ã€‚å°†ç¦ç”¨è£å‰ªåŠŸèƒ½ã€‚")
        
#         cap = cv2.VideoCapture(input_path)
#         if not cap.isOpened():
#             print(f"é”™è¯¯: æ— æ³•æ‰“å¼€è¾“å…¥è§†é¢‘ '{input_path}'")
#             return

#         frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#         frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#         fps = cap.get(cv2.CAP_PROP_FPS)

#         fourcc = cv2.VideoWriter_fourcc(*'mp4v')
#         out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

#         print(f"å¼€å§‹å¤„ç†è§†é¢‘... æŒ‰ 'q' é”®å¯æå‰ç»ˆæ­¢å¹¶ä¿å­˜å½“å‰è¿›åº¦ã€‚")
        
#         while cap.isOpened():
#             ret, frame = cap.read()
#             if not ret:
#                 break
            
#             results = self.model(frame, stream=True, conf=conf_threshold, device= '4')
#             overlay = frame.copy()
            
#             for r in results:
#                 if cropping_enabled:
#                     # ä¸å†éœ€è¦ä¼ é€’å¸§å·
#                     self.crop_and_save_objects(r, frame, target_class_id, crop_save_dir)
                
#                 boxes = r.boxes
#                 for box in boxes:
#                     bbox = box.xyxy[0]
#                     score = float(box.conf[0])
#                     class_id = int(box.cls[0])
#                     self._draw_mmdet_style_box(overlay, bbox, score, class_id)
            
#             alpha = 0.6
#             processed_frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)
#             out.write(processed_frame)

#             if cv2.waitKey(1) & 0xFF == ord('q'):
#                 print("ç”¨æˆ·æ‰‹åŠ¨ç»ˆæ­¢ã€‚")
#                 break
        
#         cap.release()
#         out.release()
#         cv2.destroyAllWindows()
#         print(f"è§†é¢‘å¤„ç†å®Œæˆã€‚ç»“æœå·²ä¿å­˜åˆ° '{output_path}'")


# if __name__ == '__main__':
#     # --- ä½¿ç”¨ç¤ºä¾‹ ---
    
#     detector = YoloDetector(model_path='./jg_project/v001-epoch100-aug/weights/best.pt') 

#     # input_video = "./datasets/test-video/720310.mp4" # ç¡®ä¿æ­¤è·¯å¾„æœ‰æ•ˆ
#     # input_video = "./datasets/test-video/343149.mp4" # ç¡®ä¿æ­¤è·¯å¾„æœ‰æ•ˆ
    
#     # input_video = "./datasets/test-video/mp4/343149-202507201602-202507201607.mp4" # ç¡®ä¿æ­¤è·¯å¾„æœ‰æ•ˆ
#     # output_video = "./inference_results/343149-202507201602-202507201607-output.mp4"

#     video_name = '343205-202507201624-202507201629'
#     # 343149-202507201602-202507201607  13
#     # 343205-202507201527-202507201530  1914
#     # 343205-202507201630-202507201639  2888
#     # 343149-202507201745-202507201751  5154
#     # 343205-202507201535-202507201539  6335
#     # 720310-202507201623-202507201635  9551
#     # 343205-202507201520-202507201527  11859
#     # 343205-202507201624-202507201629  12303
    
#     input_video = f"./datasets/test-video/mp4/{video_name}.mp4" # ç¡®ä¿æ­¤è·¯å¾„æœ‰æ•ˆ
#     output_video = f"./inference_results/{video_name}-output.mp4"




#     # å‡è®¾ 'yolov8n.pt' èƒ½æ£€æµ‹åˆ° 'bus'
#     TARGET_CLASS = 'bus'
#     CROP_SAVE_DIRECTORY = f'./inference_results/cropped_{TARGET_CLASS}/'
    
#     if detector.model:
#         detector.process_video(
#             input_path=input_video,
#             output_path=output_video,
#             conf_threshold=0.4,
#             crop_target_class_name=TARGET_CLASS,
#             crop_save_dir=CROP_SAVE_DIRECTORY
#         )










import cv2
import numpy as np
from ultralytics import YOLO
import os
from tqdm import tqdm

class YoloCropper:
    """
    ä¸€ä¸ªä¸“æ³¨äºä»è§†é¢‘æºï¼ˆæ–‡ä»¶æˆ–RTSPæµï¼‰ä¸­æ£€æµ‹ã€è£å‰ªå¹¶ä¿å­˜ç›®æ ‡ç‰©ä½“çš„å·¥å…·ç±»ã€‚
    ã€ä¼˜åŒ–ç‰ˆã€‘å¢åŠ äº†å®æ—¶è£å‰ªæ•°é‡çš„æ§åˆ¶å°è¾“å‡ºã€‚
    """

    def __init__(self, model_path: str = 'yolov8n.pt'):
        print(f"æ­£åœ¨åŠ è½½YOLOæ£€æµ‹æ¨¡å‹: {model_path}")
        try:
            self.model = YOLO(model_path)
            self.class_names = self.model.names
            self.class_name_to_id = {v: k for k, v in self.class_names.items()}
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸã€‚å¯æ£€æµ‹ç±»åˆ«: {list(self.class_names.values())}")
            self.crop_file_counter = 0
        except Exception as e:
            print(f"âŒ é”™è¯¯: æ— æ³•åŠ è½½YOLOæ¨¡å‹ã€‚è¯·æ£€æŸ¥è·¯å¾„å’Œå®‰è£…ã€‚é”™è¯¯è¯¦æƒ…: {e}")
            self.model = None

    def get_highest_file_number(self, directory: str) -> int:
        os.makedirs(directory, exist_ok=True)
        max_num = 0
        print(f"æ­£åœ¨æ‰«æç›®å½• '{directory}' ä»¥ç¡®å®šèµ·å§‹ç¼–å·...")
        try:
            for filename in os.listdir(directory):
                if filename.lower().endswith('.jpg'):
                    try:
                        num = int(os.path.splitext(filename)[0])
                        if num > max_num: max_num = num
                    except ValueError: continue
        except Exception as e: print(f"æ‰«æç›®å½•æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        print(f"æ‰«æå®Œæˆã€‚æœ€å¤§æ–‡ä»¶ç¼–å·ä¸º: {max_num}ã€‚å°†ä»ä¸‹ä¸€ä¸ªç¼–å·å¼€å§‹ä¿å­˜ã€‚")
        return max_num

    def crop_and_save_objects(self, single_frame_result, original_frame, target_class_id: int, save_dir: str):
        """
        ä»å•å¸§çš„æ£€æµ‹ç»“æœä¸­è£å‰ªå‡ºç›®æ ‡å¹¶ä¿å­˜ï¼Œå¹¶å®æ—¶æ‰“å°è®¡æ•°ã€‚
        """
        boxes = single_frame_result.boxes
        for box in boxes:
            if int(box.cls[0]) == target_class_id:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                x1_c, y1_c = max(0, x1), max(0, y1)
                x2_c, y2_c = min(original_frame.shape[1], x2), min(original_frame.shape[0], y2)
                
                if x1_c < x2_c and y1_c < y2_c:
                    cropped_object = original_frame[y1_c:y2_c, x1_c:x2_c]
                    
                    self.crop_file_counter += 1
                    filename = f"{self.crop_file_counter}.jpg"
                    save_path = os.path.join(save_dir, filename)
                    cv2.imwrite(save_path, cropped_object)
                    
                    # ã€æ ¸å¿ƒä¿®æ”¹ã€‘åœ¨æ§åˆ¶å°æ‰“å°å®æ—¶è£å‰ªæ•°é‡
                    print(f"\nâœ‚ï¸ å·²è£å‰ªå›¾ç‰‡æ•°é‡: {self.crop_file_counter}", end='\r\n')

    def process_and_crop(self, 
                         source: str, 
                         crop_target_class_name: str, 
                         crop_save_dir: str,
                         conf_threshold: float = 0.5,
                         display_window: bool = True):
        if not self.model:
            print("é”™è¯¯ï¼šYOLOæ¨¡å‹æœªåˆå§‹åŒ–ï¼Œæ— æ³•å¤„ç†ã€‚")
            return
        
        if crop_target_class_name not in self.class_name_to_id:
            print(f"âŒ é”™è¯¯ï¼šè¦è£å‰ªçš„ç›®æ ‡ç±»åˆ« '{crop_target_class_name}' ä¸å­˜åœ¨äºæ¨¡å‹çš„ç±»åˆ«åˆ—è¡¨ä¸­ã€‚")
            print(f"å¯ç”¨ç±»åˆ«ä¸º: {list(self.class_names.values())}")
            return
            
        target_class_id = self.class_name_to_id[crop_target_class_name]
        self.crop_file_counter = self.get_highest_file_number(crop_save_dir)
        print(f"âœ… è£å‰ªåŠŸèƒ½å·²å¯ç”¨ï¼šå°†è£å‰ªæ‰€æœ‰ '{crop_target_class_name}' (ID: {target_class_id}) å¹¶ä¿å­˜è‡³ '{crop_save_dir}'")

        is_stream = isinstance(source, str) and source.lower().startswith("rtsp://")
        cap = cv2.VideoCapture(source)
        if not cap.isOpened():
            print(f"âŒ é”™è¯¯: æ— æ³•æ‰“å¼€è¾“å…¥æº '{source}'")
            return

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        progress_bar = tqdm(total=total_frames, desc=f"å¤„ç† {os.path.basename(str(source))}", unit="frame", disable=is_stream)

        print(f"ğŸš€ å¼€å§‹å¤„ç† {'RTSPæµ' if is_stream else 'è§†é¢‘æ–‡ä»¶'}... æŒ‰ 'q' é”®å¯æå‰ç»ˆæ­¢ã€‚")
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                # ã€æ–°å¢ã€‘æ‰“å°æ¢è¡Œç¬¦ï¼Œé¿å…æœ€ç»ˆæ—¥å¿—è¢«è¦†ç›–
                print() 
                print("\nâ„¹ï¸ è§†é¢‘æµç»“æŸæˆ–è¯»å–å¸§å¤±è´¥ã€‚")
                break

            results = self.model(frame, stream=True, conf=conf_threshold, device='0', verbose=False)

            for r in results:
                self.crop_and_save_objects(r, frame, target_class_id, crop_save_dir)

            if display_window:
                cv2.imshow('YOLOv8 Cropping Pipeline (Original Stream)', frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    # ã€æ–°å¢ã€‘æ‰“å°æ¢è¡Œç¬¦
                    print()
                    print("\nç”¨æˆ·æ‰‹åŠ¨ç»ˆæ­¢ã€‚")
                    break
            
            if not is_stream:
                progress_bar.update(1)
        
        cap.release()
        if display_window:
            cv2.destroyAllWindows()
        if not is_stream:
            progress_bar.close()
        
        # ã€æ–°å¢ã€‘åœ¨æµç¨‹ç»“æŸåå†æ¬¡æ‰“å°æœ€ç»ˆç»“æœ
        print() # æ¢è¡Œ
        print(f"å¤„ç†æµç¨‹ç»“æŸã€‚æœ€ç»ˆå…±è£å‰ªäº† {self.crop_file_counter} å¼ å›¾ç‰‡,ä¿å­˜åœ¨{crop_save_dir}ã€‚")

def run(model_path, 
        INPUT_SOURCE,
        TARGET_CLASS_TO_CROP,
        CROP_SAVE_DIRECTORY= './inference_results/test/bus_crops_from_rtsp', 
        CONFIDENCE_THRESHOLD= 0.45,
        DISPLAY_REALTIME_WINDOW= False):
    # 1. å®ä¾‹åŒ–è£å‰ªå™¨
    cropper = YoloCropper(model_path='./jg_project/v001-epoch100-aug/weights/best.pt')

    # --- å‚æ•°é…ç½® ---
    # ... (è¿™éƒ¨åˆ†å’Œæ‚¨æä¾›çš„ä¸€æ ·ï¼Œæ— éœ€ä¿®æ”¹) ...
    # video_name = '343205-202507201624-202507201629'
    # INPUT_SOURCE = f"./datasets/test-video/mp4/{video_name}.mp4"
    INPUT_SOURCE = f'rtsp://localhost:8556/test-crop'
    
    TARGET_CLASS_TO_CROP = 'bus'
    CROP_SAVE_DIRECTORY = f'./inference_results/test/bus_crops_from_rtsp/'
    CONFIDENCE_THRESHOLD = 0.45
    
    DISPLAY_REALTIME_WINDOW = False # è®¾ä¸ºFalseå¯åœ¨æœåŠ¡å™¨ä¸Šæ— ç•Œé¢è¿è¡Œ

    # --- è¿è¡Œå¤„ç† ---
    if cropper.model:
        cropper.process_and_crop(
            source=INPUT_SOURCE,
            crop_target_class_name=TARGET_CLASS_TO_CROP,
            crop_save_dir=CROP_SAVE_DIRECTORY,
            conf_threshold=CONFIDENCE_THRESHOLD,
            display_window=DISPLAY_REALTIME_WINDOW
        )
if __name__ == '__main__':
    # 1. å®ä¾‹åŒ–è£å‰ªå™¨
    cropper = YoloCropper(model_path='./jg_project/v001-epoch100-aug/weights/best.pt')

    # --- å‚æ•°é…ç½® ---
    # ... (è¿™éƒ¨åˆ†å’Œæ‚¨æä¾›çš„ä¸€æ ·ï¼Œæ— éœ€ä¿®æ”¹) ...
    # video_name = '343205-202507201624-202507201629'
    # INPUT_SOURCE = f"./datasets/test-video/mp4/{video_name}.mp4"
    INPUT_SOURCE = f'rtsp://localhost:8556/test-crop'
    
    TARGET_CLASS_TO_CROP = 'bus'
    CROP_SAVE_DIRECTORY = f'./inference_results/test/bus_crops_from_rtsp/'
    CONFIDENCE_THRESHOLD = 0.45
    
    DISPLAY_REALTIME_WINDOW = False # è®¾ä¸ºFalseå¯åœ¨æœåŠ¡å™¨ä¸Šæ— ç•Œé¢è¿è¡Œ

    # --- è¿è¡Œå¤„ç† ---
    if cropper.model:
        cropper.process_and_crop(
            source=INPUT_SOURCE,
            crop_target_class_name=TARGET_CLASS_TO_CROP,
            crop_save_dir=CROP_SAVE_DIRECTORY,
            conf_threshold=CONFIDENCE_THRESHOLD,
            display_window=DISPLAY_REALTIME_WINDOW
        )