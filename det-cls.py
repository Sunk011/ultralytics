# import os
# import cv2
# from ultralytics import YOLO
# from tqdm import tqdm
# import time
# from datetime import datetime

# class TwoStagePipeline:
#     """
#     ä¸€ä¸ªå®ç°ä¸¤é˜¶æ®µæ£€æµ‹æµç¨‹çš„ç®¡é“ã€‚
#     æ”¯æŒå›¾ç‰‡ã€è§†é¢‘æ–‡ä»¶å’ŒRTSPæµçš„æ¨ç†ï¼Œå¹¶æä¾›çµæ´»çš„ä¿å­˜é€‰é¡¹ã€‚
#     """
#     def __init__(self, detection_model_path: str, classification_model_path: str):
#         print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
#         try:
#             self.detector = YOLO(detection_model_path)
#             self.classifier = YOLO(classification_model_path)
#             self.classifier_names = self.classifier.names
#             print("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½æˆåŠŸã€‚")
#             print(f"æ£€æµ‹å™¨ç±»åˆ«: {list(self.detector.names.values())[:5]}...") # æ˜¾ç¤ºéƒ¨åˆ†æ£€æµ‹ç±»åˆ«
#             print(f"åˆ†ç±»å™¨ç±»åˆ«: {list(self.classifier_names.values())}")
#         except Exception as e:
#             raise IOError(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}")

#     def _draw_result(self, image, box, label: str, confidence: float):
#         """åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶å•ä¸ªç»“æœæ¡†å’Œæ ‡ç­¾çš„è¾…åŠ©å‡½æ•°ã€‚"""
#         x1, y1, x2, y2 = map(int, box)
#         is_target = "positive" in label.lower() or "target" in label.lower() # å‡è®¾æ­£æ ·æœ¬æ–‡ä»¶å¤¹åä¸º positive_samples
#         color = (0, 220, 0) if is_target else (0, 0, 220)
        
#         cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
#         display_text = f"{label} ({confidence:.2f})"
#         font = cv2.FONT_HERSHEY_SIMPLEX
#         font_scale = 0.8
#         font_thickness = 2
#         (text_w, text_h), baseline = cv2.getTextSize(display_text, font, font_scale, font_thickness)
#         cv2.rectangle(image, (x1, y1 - text_h - baseline - 5), (x1 + text_w, y1), color, -1)
#         cv2.putText(image, display_text, (x1, y1 - 5), font, font_scale, (255, 255, 255), font_thickness)

#     def _process_frame(self, frame, target_detection_class: str = 'bus', conf_threshold: float = 0.4):
#         """å¤„ç†å•å¸§å›¾åƒçš„å†…éƒ¨æ ¸å¿ƒé€»è¾‘ã€‚"""
#         # --- é˜¶æ®µä¸€ï¼šæ£€æµ‹ ---
#         print(f"æ­£åœ¨æ£€æµ‹ç›®æ ‡: {target_detection_class} (ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold})", end='\r')
#         det_results = self.detector(frame, conf=conf_threshold, classes=[list(self.detector.names.values()).index(target_detection_class)], verbose=False)
        
        
#         # --- é˜¶æ®µäºŒï¼šåˆ†ç±» ---
#         for box in det_results[0].boxes:
#             x1, y1, x2, y2 = map(int, box.xyxy[0])
#             x1, y1 = max(0, x1), max(0, y1)
#             x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)
#             if x1 >= x2 or y1 >= y2: continue
                
#             cropped_img = frame[y1:y2, x1:x2]
#             cls_results = self.classifier(cropped_img, verbose=False)
            
#             top1_index = cls_results[0].probs.top1
#             top1_confidence = cls_results[0].probs.top1conf
#             predicted_class_name = self.classifier_names[top1_index]
            
#             self._draw_result(frame, box.xyxy[0], predicted_class_name, top1_confidence)
        
#         return frame

#     def _process_video_or_stream(self, source, output_dir: str, save_results: bool, rtsp_segment_time: int = 60):
#         """å¤„ç†è§†é¢‘æ–‡ä»¶æˆ–å®æ—¶æµçš„å†…éƒ¨æ–¹æ³•ã€‚"""
#         cap = cv2.VideoCapture(source)
#         if not cap.isOpened():
#             print(f"é”™è¯¯: æ— æ³•æ‰“å¼€è§†é¢‘æº '{source}'")
#             return

#         is_rtsp = isinstance(source, str) and source.lower().startswith("rtsp://")
        
#         video_writer = None
#         segment_start_time = time.time()
        
#         # å¦‚æœæ˜¯æ™®é€šè§†é¢‘æ–‡ä»¶ï¼Œé¢„å…ˆè®¾ç½®å¥½VideoWriter
#         if save_results and not is_rtsp:
#             fps = int(cap.get(cv2.CAP_PROP_FPS))
#             width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#             height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#             fourcc = cv2.VideoWriter_fourcc(*'mp4v')
#             filename = f"output_{os.path.basename(source)}"
#             output_path = os.path.join(output_dir, filename)
#             video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
#             print(f"å°†ä¿å­˜å¤„ç†åçš„è§†é¢‘åˆ°: {output_path}")

#         while True:
#             ret, frame = cap.read()
#             if not ret:
#                 print("è§†é¢‘æµç»“æŸæˆ–è¯»å–å¸§å¤±è´¥ã€‚")
#                 break
            
#             # --- RTSPåˆ†æ®µä¿å­˜é€»è¾‘ ---
#             if save_results and is_rtsp:
#                 current_time = time.time()
#                 # å¦‚æœå½“å‰åˆ†æ®µå·²è¾¾åˆ°æ—¶é•¿ï¼Œåˆ™å…³é—­å½“å‰writer
#                 if video_writer and (current_time - segment_start_time >= rtsp_segment_time):
#                     video_writer.release()
#                     video_writer = None
#                     print(f"RTSPå·²åˆ†æ®µã€‚")
                
#                 # å¦‚æœæ²¡æœ‰writerï¼Œåˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
#                 if not video_writer:
#                     segment_start_time = current_time
#                     timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
#                     filename = f"rtsp_segment_{timestamp}.mp4"
#                     output_path = os.path.join(output_dir, filename)
                    
#                     fps = int(cap.get(cv2.CAP_PROP_FPS)) if cap.get(cv2.CAP_PROP_FPS) > 0 else 25 # é»˜è®¤25fps
#                     width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#                     height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#                     fourcc = cv2.VideoWriter_fourcc(*'mp4v')
#                     video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
#                     print(f"å¼€å§‹å½•åˆ¶æ–°çš„è§†é¢‘åˆ†æ®µ: {output_path}")

#             processed_frame = self._process_frame(frame.copy())

#             # å¦‚æœéœ€è¦ä¿å­˜ï¼Œåˆ™å†™å…¥å¸§
#             if save_results and video_writer:
#                 video_writer.write(processed_frame)

#             # å®æ—¶æ˜¾ç¤ºç»“æœ
#             # cv2.imshow("Two-Stage Pipeline", processed_frame)
#             if cv2.waitKey(1) & 0xFF == ord('q'):
#                 print("ç”¨æˆ·æ‰‹åŠ¨ç»ˆæ­¢ã€‚")
#                 break
        
#         # é‡Šæ”¾èµ„æº
#         if video_writer:
#             video_writer.release()
#         cap.release()
#         cv2.destroyAllWindows()

#     def process(self, source, save_results: bool = False, output_image_dir: str = 'outputs/images', output_video_dir: str = 'outputs/videos', output_rtsp_dir: str = 'outputs/rtsp_segments', rtsp_segment_time: int = 60):
#         """
#         ç»Ÿä¸€çš„å¤„ç†å…¥å£ï¼Œè‡ªåŠ¨è¯†åˆ«è¾“å…¥æºç±»å‹ã€‚

#         Args:
#             source (str or int): è¾“å…¥æºã€‚å¯ä»¥æ˜¯å›¾ç‰‡è·¯å¾„, è§†é¢‘è·¯å¾„, RTSP URL, æˆ–æ‘„åƒå¤´ç´¢å¼•(0, 1, ...).
#             save_results (bool): æ˜¯å¦ä¿å­˜å¤„ç†ç»“æœã€‚
#             output_image_dir (str): ä¿å­˜å¤„ç†åå›¾ç‰‡çš„ç›®å½•ã€‚
#             output_video_dir (str): ä¿å­˜å¤„ç†åè§†é¢‘çš„ç›®å½•ã€‚
#             output_rtsp_dir (str): ä¿å­˜RTSPæµåˆ†æ®µçš„ç›®å½•ã€‚
#             rtsp_segment_time (int): RTSPæµåˆ†æ®µä¿å­˜çš„æ—¶é•¿ï¼ˆç§’ï¼‰ã€‚
#         """
#         # åˆ›å»ºæ‰€æœ‰è¾“å‡ºç›®å½•
#         os.makedirs(output_image_dir, exist_ok=True)
#         os.makedirs(output_video_dir, exist_ok=True)
#         os.makedirs(output_rtsp_dir, exist_ok=True)
        
#         # --- åˆ¤æ–­è¾“å…¥æºç±»å‹ ---
#         source_str = str(source).lower()
#         if source_str.endswith(('.jpg', '.jpeg', '.png', '.bmp')):
#             # å¤„ç†å•å¼ å›¾ç‰‡
#             filename = os.path.basename(source)
#             output_path = os.path.join(output_image_dir, f"output_{filename}")
#             frame = cv2.imread(source)
#             frame = frame.copy()
#             if frame is None:
#                 print(f"é”™è¯¯: æ— æ³•è¯»å–å›¾ç‰‡ '{source}'")
#                 return
#             processed_frame = self._process_frame(frame)
#             if save_results:
#                 cv2.imwrite(output_path, processed_frame)
#                 print(f"å¤„ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {output_path}")
#             # cv2.imshow("Two-Stage Pipeline", processed_frame)
#             cv2.waitKey(0)
#             cv2.destroyAllWindows()
            
#         elif source_str.startswith("rtsp://"):
#             # å¤„ç†RTSPæµ
#             print("æ£€æµ‹åˆ°RTSPæµï¼Œå¼€å§‹å¤„ç†...")
#             self._process_video_or_stream(source, output_rtsp_dir, save_results, rtsp_segment_time)
        
#         else:
#             # å¤„ç†è§†é¢‘æ–‡ä»¶æˆ–æ‘„åƒå¤´
#             print("æ£€æµ‹åˆ°è§†é¢‘æ–‡ä»¶æˆ–æ‘„åƒå¤´ï¼Œå¼€å§‹å¤„ç†...")
#             self._process_video_or_stream(source, output_video_dir, save_results)


# # --- ä½¿ç”¨ç¤ºä¾‹ ---
# if __name__ == '__main__':
#     # 1. è®¾ç½®æ¨¡å‹è·¯å¾„
#     DETECTION_MODEL_PATH = r'./jg_project/v001-epoch100-aug/weights/best.pt'
#     CLASSIFICATION_MODEL_PATH = r'./jg_project/cls/test3/weights/best.pt' # <--- ä¿®æ”¹è¿™é‡Œ

#     # 2. è®¾ç½®ä¿å­˜é€‰é¡¹å’Œç›®å½•
#     SAVE_RESULTS = True  # True: ä¿å­˜æ‰€æœ‰ç»“æœ, False: åªå®æ—¶æ˜¾ç¤ºä¸ä¿å­˜
    
#     OUTPUT_IMAGE_DIR = 'inference_outputs/test/images'
#     OUTPUT_VIDEO_DIR = 'inference_outputs/test/videos'
#     OUTPUT_RTSP_DIR = 'inference_outputs/test/rtsp_segments'
#     RTSP_SEGMENT_DURATION_SECONDS = 90 # 1åˆ†é’Ÿ

#     # 3. åˆ›å»ºç®¡é“å®ä¾‹
#     try:
#         pipeline = TwoStagePipeline(
#             detection_model_path=DETECTION_MODEL_PATH,
#             classification_model_path=CLASSIFICATION_MODEL_PATH
#         )
        
#         # --- æ ¹æ®ä½ çš„éœ€æ±‚ï¼Œé€‰æ‹©ä¸€ç§è¾“å…¥æºæ¥è¿è¡Œ ---

#         # === ç¤ºä¾‹1: å¤„ç†å•å¼ å›¾ç‰‡ ===
#         # INPUT_SOURCE = 'path/to/your/street_view.jpg' # <--- ä¿®æ”¹è¿™é‡Œ

#         # === ç¤ºä¾‹2: å¤„ç†æœ¬åœ°è§†é¢‘æ–‡ä»¶ ===
#         INPUT_SOURCE = '/home/sk/project/datasets/test-video/mp4/343149-202507201602-202507201607.mp4' # <--- ä¿®æ”¹è¿™é‡Œ

#         # === ç¤ºä¾‹3: å¤„ç†RTSPè§†é¢‘æµ ===
#         # INPUT_SOURCE = 'rtsp://username:password@ip_address:port/stream_path' # <--- ä¿®æ”¹è¿™é‡Œ
        
#         # 4. è¿è¡Œç®¡é“
#         pipeline.process(
#             source=INPUT_SOURCE,
#             save_results=SAVE_RESULTS,
#             output_image_dir=OUTPUT_IMAGE_DIR,
#             output_video_dir=OUTPUT_VIDEO_DIR,
#             output_rtsp_dir=OUTPUT_RTSP_DIR,
#             rtsp_segment_time=RTSP_SEGMENT_DURATION_SECONDS
#         )

#     except Exception as e:
#         print(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        
        








import os
import cv2
from ultralytics import YOLO
from tqdm import tqdm # å¼•å…¥tqdmè¿›åº¦æ¡åº“
import time
from datetime import datetime

class TwoStagePipeline:
    """
    ä¸€ä¸ªå®ç°ä¸¤é˜¶æ®µæ£€æµ‹æµç¨‹çš„ç®¡é“ã€‚
    æ”¯æŒå›¾ç‰‡ã€è§†é¢‘æ–‡ä»¶å’ŒRTSPæµçš„æ¨ç†ï¼Œå¹¶æä¾›çµæ´»çš„ä¿å­˜é€‰é¡¹ã€‚
    ã€ä¼˜åŒ–ç‰ˆã€‘
    """
    def __init__(self, detection_model_path: str, classification_model_path: str):
        print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
        try:
            self.detector = YOLO(detection_model_path)
            self.classifier = YOLO(classification_model_path)
            self.classifier_names = self.classifier.names
            print("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½æˆåŠŸã€‚")
            print(f"æ£€æµ‹å™¨ç±»åˆ«: {list(self.detector.names.values())[:5]}...")
            print(f"åˆ†ç±»å™¨ç±»åˆ«: {list(self.classifier_names.values())}")
        except Exception as e:
            raise IOError(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}")

    def _draw_result(self, image, box, label: str, confidence: float):
        """åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶å•ä¸ªç»“æœæ¡†å’Œæ ‡ç­¾çš„è¾…åŠ©å‡½æ•°ã€‚"""
        x1, y1, x2, y2 = map(int, box)
        # ã€ä¼˜åŒ–ã€‘å‡è®¾æ­£æ ·æœ¬ç±»åˆ«åä¸º 'target_bus'
        is_target = "target_bus" in label.lower()
        color = (0, 220, 0) if is_target else (0, 0, 220)
        
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
        display_text = f"{label} ({confidence:.2f})"
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.8
        font_thickness = 2
        (text_w, text_h), baseline = cv2.getTextSize(display_text, font, font_scale, font_thickness)
        cv2.rectangle(image, (x1, y1 - text_h - baseline - 5), (x1 + text_w, y1), color, -1)
        cv2.putText(image, display_text, (x1, y1 - 5), font, font_scale, (255, 255, 255), font_thickness)

    def _process_frame(self, frame, target_detection_class: str, conf_threshold: float):
        """å¤„ç†å•å¸§å›¾åƒçš„å†…éƒ¨æ ¸å¿ƒé€»è¾‘ã€‚"""
        # --- é˜¶æ®µä¸€ï¼šæ£€æµ‹ ---
        det_results = self.detector(frame, conf=conf_threshold, classes=[list(self.detector.names.values()).index(target_detection_class)], verbose=False)
        
        # print(f"\ndet_resutls:\n{det_results}")
        
        # --- é˜¶æ®µäºŒï¼šåˆ†ç±» ---
        for box in det_results[0].boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)
            if x1 >= x2 or y1 >= y2: continue
                
            cropped_img = frame[y1:y2, x1:x2]
            cls_results = self.classifier(cropped_img, verbose=False)
            
            top1_index = cls_results[0].probs.top1
            top1_confidence = cls_results[0].probs.top1conf
            predicted_class_name = self.classifier_names[top1_index]
            
            # ä»…ç»˜åˆ¶åˆ†ç±»ä¸ºtarget_busçš„ç›®æ ‡
            if predicted_class_name == 'target_bus':
                self._draw_result(frame, box.xyxy[0], predicted_class_name, top1_confidence)
        
        return frame

    def _process_video_or_stream(self, source, output_dir: str, save_results: bool, target_detection_class: str, conf_threshold: float, rtsp_segment_time: int):
        """å¤„ç†è§†é¢‘æ–‡ä»¶æˆ–å®æ—¶æµçš„å†…éƒ¨æ–¹æ³•ã€‚"""
        cap = cv2.VideoCapture(source)
        if not cap.isOpened():
            print(f"âŒ é”™è¯¯: æ— æ³•æ‰“å¼€è§†é¢‘æº '{source}'ã€‚è¯·æ£€æŸ¥è·¯å¾„æˆ–RTSP URLæ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠæ–‡ä»¶æ˜¯å¦æŸåæˆ–ç¼ºå°‘è§£ç å™¨ã€‚")
            return

        is_rtsp = isinstance(source, str) and source.lower().startswith("rtsp://")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS) if cap.get(cv2.CAP_PROP_FPS) > 0 else 25
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        print(f"ğŸ“¹ è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps:.2f} FPS, å…± {total_frames if not is_rtsp else 'N/A'} å¸§ã€‚")

        video_writer = None
        # segment_start_time = time.time()
        
        if save_results and not is_rtsp:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            base_name = os.path.basename(source)
            filename = f"output_{os.path.splitext(base_name)[0]}.mp4"
            output_path = os.path.join(output_dir, filename)
            video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            print(f"ğŸ’¾ å°†ä¿å­˜å¤„ç†åçš„è§†é¢‘åˆ°: {output_path}")

        # ä¸ºæœ¬åœ°è§†é¢‘æ·»åŠ è¿›åº¦æ¡
        progress_bar = tqdm(total=total_frames, desc="å¤„ç†è§†é¢‘ä¸­", unit="frame", disable=is_rtsp)

        while True:
            ret, frame = cap.read()
            if not ret:
                if not is_rtsp: print("\nâœ… è§†é¢‘å¤„ç†å®Œæˆã€‚") 
                else: print("â„¹ï¸ è§†é¢‘æµç»“æŸæˆ–è¯»å–å¸§å¤±è´¥ã€‚")
                break
            
            # # RTSPåˆ†æ®µä¿å­˜é€»è¾‘
            # if save_results and is_rtsp:
            #     segment_start_time = current_time
            #     timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            #     filename = f"rtsp_segment_{timestamp}.mp4"
            #     output_path = os.path.join(output_dir, filename)
                
            #     fps = int(cap.get(cv2.CAP_PROP_FPS)) if cap.get(cv2.CAP_PROP_FPS) > 0 else 25 # é»˜è®¤25fps
            #     width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            #     height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            #     fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            #     video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            #     print(f"å¼€å§‹å½•åˆ¶æ–°çš„è§†é¢‘åˆ†æ®µ: {output_path}")

            # ã€ä¿®å¤ã€‘å°†å‚æ•°æ­£ç¡®ä¼ é€’ç»™_process_frame
            processed_frame = self._process_frame(frame.copy(), target_detection_class, conf_threshold)

            if save_results and video_writer:
                video_writer.write(processed_frame)

            # cv2.imshow("Two-Stage Pipeline", processed_frame) # æœåŠ¡å™¨è¿è¡Œæ—¶æ³¨é‡Šæ‰
            if cv2.waitKey(1) & 0xFF == ord('q'):
                print("ç”¨æˆ·æ‰‹åŠ¨ç»ˆæ­¢ã€‚")
                break
            
            if not is_rtsp:
                progress_bar.update(1)
        
        if video_writer: video_writer.release()
        cap.release()
        cv2.destroyAllWindows()
        if not is_rtsp: progress_bar.close()

    def process(self, source, save_results: bool = False, output_image_dir: str = 'outputs/images', output_video_dir: str = 'outputs/videos', output_rtsp_dir: str = 'outputs/rtsp_segments', rtsp_segment_time: int = 60, target_detection_class: str = 'bus', conf_threshold: float = 0.4):
        """ç»Ÿä¸€çš„å¤„ç†å…¥å£ï¼Œè‡ªåŠ¨è¯†åˆ«è¾“å…¥æºç±»å‹ã€‚"""
        os.makedirs(output_image_dir, exist_ok=True)
        os.makedirs(output_video_dir, exist_ok=True)
        os.makedirs(output_rtsp_dir, exist_ok=True)
        
        source_str = str(source).lower()
        if source_str.endswith(('.jpg', '.jpeg', '.png', '.bmp')):
            frame = cv2.imread(source)
            if frame is None:
                print(f"âŒ é”™è¯¯: æ— æ³•è¯»å–å›¾ç‰‡ '{source}'")
                return
            
            # ã€ä¿®å¤ã€‘å°†å‚æ•°æ­£ç¡®ä¼ é€’ç»™_process_frame
            processed_frame = self._process_frame(frame.copy(), target_detection_class, conf_threshold)
            
            if save_results:
                filename = os.path.basename(source)
                output_path = os.path.join(output_image_dir, f"output_{filename}")
                cv2.imwrite(output_path, processed_frame)
                print(f"å¤„ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {output_path}")
            
            cv2.imshow("Two-Stage Pipeline", processed_frame)
            cv2.waitKey(0)
            cv2.destroyAllWindows()
            
        elif source_str.startswith("rtsp://"):
            print("æ£€æµ‹åˆ°RTSPæµï¼Œå¼€å§‹å¤„ç†...")
            # ã€ä¿®å¤ã€‘å°†å‚æ•°æ­£ç¡®ä¼ é€’
            self._process_video_or_stream(source, output_rtsp_dir, save_results, target_detection_class, conf_threshold, rtsp_segment_time)
        
        else:
            print("æ£€æµ‹åˆ°è§†é¢‘æ–‡ä»¶æˆ–æ‘„åƒå¤´ï¼Œå¼€å§‹å¤„ç†...")
            # ã€ä¿®å¤ã€‘å°†å‚æ•°æ­£ç¡®ä¼ é€’
            self._process_video_or_stream(source, output_video_dir, save_results, target_detection_class, conf_threshold, rtsp_segment_time)

# --- ä½¿ç”¨ç¤ºä¾‹ ---
if __name__ == '__main__':
    # 1. è®¾ç½®æ¨¡å‹è·¯å¾„
    DETECTION_MODEL_PATH = r'./jg_project/v001-epoch100-aug/weights/best.pt'
    CLASSIFICATION_MODEL_PATH = r'./jg_project/cls/test3/weights/best.pt'

    # 2. è®¾ç½®æ¨ç†å‚æ•°
    SAVE_RESULTS = True
    TARGET_CLASS = 'bus' # ç¡®ä¿ä½ çš„æ£€æµ‹å™¨èƒ½è¯†åˆ«è¿™ä¸ªç±»åˆ«
    CONF_THRESHOLD = 0.45

    # 3. è®¾ç½®è¾“å‡ºç›®å½•
    OUTPUT_IMAGE_DIR = 'inference_outputs/test/images'
    OUTPUT_VIDEO_DIR = 'inference_outputs/test/videos'
    OUTPUT_RTSP_DIR = 'inference_outputs/test/rtsp_segments'
    RTSP_SEGMENT_DURATION_SECONDS = 90

    # 4. åˆ›å»ºç®¡é“å®ä¾‹
    try:
        pipeline = TwoStagePipeline(
            detection_model_path=DETECTION_MODEL_PATH,
            classification_model_path=CLASSIFICATION_MODEL_PATH
        )
        
        # --- é€‰æ‹©ä¸€ç§è¾“å…¥æº ---
        # INPUT_SOURCE = 'path/to/image.jpg'
        INPUT_SOURCE = '/home/sk/project/datasets/test-video/mp4/343149-202507201602-202507201607.mp4'
        # INPUT_SOURCE = 'rtsp://...'
        
        # 5. è¿è¡Œç®¡é“
        pipeline.process(
            source=INPUT_SOURCE,
            save_results=SAVE_RESULTS,
            output_image_dir=OUTPUT_IMAGE_DIR,
            output_video_dir=OUTPUT_VIDEO_DIR,
            output_rtsp_dir=OUTPUT_RTSP_DIR,
            rtsp_segment_time=RTSP_SEGMENT_DURATION_SECONDS,
            target_detection_class=TARGET_CLASS,
            conf_threshold=CONF_THRESHOLD
        )

    except Exception as e:
        print(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")